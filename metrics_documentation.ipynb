{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for Quality Metrics Calculation\n",
    "\n",
    "This notebook provides an overview of the four core scripts developed to compute quality metrics using BAM/CRAM files:\n",
    "- samtools_stats.py   → alignment statistics\n",
    "- depth.py            → per-position depth\n",
    "- plot.py             → visual coverage plot\n",
    "- coverage_metrics.py → coverage metrics\n",
    "\n",
    "The scripts form a sequential pipeline where each step depends on the previous one, ultimately producing both a statistics and coverage metrics report, as well as a graphical representation of the sequencing depth.\n",
    "\n",
    "The pipeline requires:\n",
    "- A BAM/CRAM file (alignment data)\n",
    "- A BED file (regions of interest)\n",
    "\n",
    "In the following section, it will demonstrate how to use the provided scripts to process genomic data. As part of this demonstration, it will first need to download an example CRAM file from the 1000 Genomes Project. To do so, please run the command below in your terminal to retrieve the file directly from the public AWS S3 bucket without authentication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://1000genomes/phase3/data/HG00099/exome_alignment/HG00099.mapped.ILLUMINA.bwa.GBR.exome.20130415.bam.cram . --no-sign-request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another required file for this workflow is a BED file containing the genomic coordinates of the gene of interest. In the following code block, a BED file is automatically generated by retrieving gene information from the Ensembl database. This file will then be used in the subsequent steps of the demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Gene Name\n",
    "gene_name = \"BRCA1\"\n",
    "\n",
    "# URL for ensembl\n",
    "url = f\"https://rest.ensembl.org/lookup/symbol/homo_sapiens/{gene_name}?content-type=application/json\"\n",
    "\n",
    "# API request\n",
    "response = requests.get(url)\n",
    "\n",
    "# Verificar se correu bem\n",
    "if not response.ok:\n",
    "    print(f\"Erro with data for {gene_name}.\")\n",
    "else:\n",
    "    data = response.json()\n",
    "    chrom = data[\"seq_region_name\"]\n",
    "    start = data[\"start\"]\n",
    "    end = data[\"end\"]\n",
    "    name = data[\"display_name\"]\n",
    "    exon = 'Exon'\n",
    "    size = data['end'] - data['start']\n",
    "\n",
    "    # BED File Creation\n",
    "    with open(\"genes.bed\", \"a\") as f:\n",
    "        f.write(f\"{chrom}\\t{start}\\t{end}\\t{name}\\t{exon}\\t{size}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After securing both required files, it is now possible to proceed with the pipeline. The general workflow can be represented as:\n",
    "\n",
    "```arduino\n",
    "BAM/CRAM + BED ──▶ samtools_stats.py ──▶ depth.py ──▶ plot.py ──▶ coverage_metrics.py ──▶ metrics report + coverage plot\n",
    "```\n",
    "\n",
    "Therefore, these scripts are interconnected in a very peculiar way. Firstly, the statistics in the BAM/CRAM file are collected, allowing the quality of these data to be analyzed. Then, the BAM/CRAM file is filtered by a BED file and, therefore, the calculation of depth and, consequently, the coverage metrics are only carried out for the interval present in this file. In addition, an interactive coverage plot is generated.\n",
    "\n",
    "**samtools_stats.py**\n",
    "\n",
    "To extract a comprehensive statistical summary of a BAM/CRAM file, one of the backend modules relies on the `pysam` library, specifically the **pysam.samtools.stats()** function, which provides a Python interface to the `samtools stats` command-line utility, offering improved speed and less computational demand. This allows for automated, reproducible extraction and post-processing of key sequencing metrics.\n",
    "\n",
    "It provides key indicators such as:\n",
    "- Total Reads\n",
    "- Total Bases\n",
    "- Average Base Quality\n",
    "- Read Length (Max)\n",
    "- Reads Mapped (%)\n",
    "- Mapping Quality 0 (%)\n",
    "- Error rate\n",
    "- Insert Size (Avg)\n",
    "- Insert Size (Std)\n",
    "- Reads paired (%)\n",
    "- Reads properly paired (%)\n",
    "- Duplicate Reads (%)\n",
    "- Proportion of duplicated reads\n",
    "\n",
    "The script calls `pysam.samtools.stats()` to execute the underlying command, capturing its multi-line text output for parsing. The extracted data includes both directly reported values, such as total reads, reads mapped, and average base quality, as well as values that need to be calculated, namely mapping quality and percentage of duplicated reads. After computation, the metrics are transformed into a pandas DataFrame.\n",
    "\n",
    "**depth.py**\n",
    "\n",
    "Depth of coverage and breadth of coverage are critical metrics for assessing the reliability of sequencing data in specific genomic regions. This module extracts the depth information for each base indicated in the regions defined in a BED file, enabling a detailed evaluation of coverage uniformity across gene or exons of interest.\n",
    "\n",
    "This script starts to process the information in the BED file in order to create a pandad dataframe with key genomic coordinates, such as chromosome, start position, end position, and gene/exon labels if gene or exon were selected.\n",
    "\n",
    "After creating the BED format dataframe, it is possible to extract the depth. The depth extraction is implemented by three different methods: `samtools depth`, a command line tool that computes the read depth; `pysam.depth`, a Python module that replicates the functionality of samtools depth; and `pysam.coverage`, a Python-based method that provides a fast and efficient way to calculate sequencing depth.\n",
    "\n",
    "In the end, a pandas DataFrame is created with chromosome, position and the respective depth in every depth extraction method. The result can be stored as a tabular file.\n",
    "\n",
    "**plot.py**\n",
    "\n",
    "The aim of this script is to create a coverage plot that enables viewing the distribution of coverage for a specific genomic region. Thus, is responsible for generating an interactive depth of coverage visualization. In order to establish a proper workflow, this function relates to the script described above. That way, after having the depth information, the resulting values are annotated with gene and exon identifiers provided by the BED input.\n",
    "\n",
    "The core of the plotting logic builds three main traces: the coverage line, the mean coverage line, and a line representing the quality threshold. To enhance interpretability, the function display discontinuities between non-contiguous positions, avoiding misleading connections across genomic gaps. In addition, regions where coverage falls below the threshold are highlighted by a shaded red area. Exon regions are emphasized by overlaying transparent rectangles defined in the shapes attribute of the Plotly layout. In the end, the plot can be returned for display or saved to disk.\n",
    "\n",
    "**coverage_metrics.py**\n",
    "\n",
    "After computing depth extraction, it is essential to translate this information into interpretable coverage metrics. That way, this module calculates metrics such as average, minimum, maximum and median read depth, depth of coverage at different thresholds (1x, 10x, 15x, 20x, 30x, 50x, 100x, 500x), and breadth of coverage. These metrics are fundamental for assessing the reliability of variant detection and overall sequencing quality. Moreover, this module aggregates the summary statistics computed earlier to have a full and unique report for each BAM/CRAM file.\n",
    "\n",
    "Like in the previous modules, all these metrics are stored in a pandas DataFrame. This way, it ensures that all the metrics calculated are easily compared, aggregated, or exported for downstream quality control and reporting.\n",
    "\n",
    "Contrarily to the samtools stats module, this script extends the coverage assessment to a different level by implementing functions that calculate metrics for individual genes and exons.\n",
    "\n",
    "Finally, as reported, this script functions as an integrative module that connects all the scripts described above. This way, this script imports the quality metrics extracted by *samtools_stats*, extracts depth information, generates the interactive plot and then applies the coverage metrics calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.coverage_metrics import calculate_metrics\n",
    "from backend.depth import filter_bed\n",
    "\n",
    "# Path for required files\n",
    "cram_path = 'HG00099.mapped.ILLUMINA.bwa.GBR.exome.20130415.bam.cram'\n",
    "bed_path = 'genes.bed'\n",
    "ref_cache = './data/reference_genome'\n",
    "\n",
    "\n",
    "# Step 1: Create BED_df\n",
    "bed_df = filter_bed(bed_path)\n",
    "print(bed_df)\n",
    "\n",
    "metrics_df = calculate_metrics(cram_path, bed_df, stats=True, ref_cache=ref_cache)\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the scripts provided can be used in two ways: either as standalone modules, which can be imported and called individually, or integrated directly into the full pipeline. This flexibility allows users to test specific functions or run the complete workflow depending on their needs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import backend modules\n",
    "from backend.samtools_stats import calculate_stats\n",
    "from backend.depth import filter_bed, get_depth_data\n",
    "from backend.plot import coverage_plot\n",
    "from backend.coverage_metrics import calculate_coverage_metrics\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Path for required files\n",
    "cram_path = 'HG00099.mapped.ILLUMINA.bwa.GBR.exome.20130415.bam.cram'\n",
    "bed_path = 'genes.bed'\n",
    "ref_cache = './data/reference_genome'\n",
    "\n",
    "# Statistical metrics extraction\n",
    "stats_df = calculate_stats(cram_path, ref_cache)\n",
    "print(stats_df)\n",
    "\n",
    "# Depth extraction\n",
    "bed_df = filter_bed(bed_path, gene_selection='BRCA1')\n",
    "depth_df = get_depth_data(cram_path, bed_df)\n",
    "\n",
    "# Coverage plot\n",
    "fig = coverage_plot(cram_path, bed_df)\n",
    "fig.show()\n",
    "\n",
    "# Coverage metrics calculation\n",
    "coverage_df = calculate_coverage_metrics(depth_df['DEPTH'], bed_df['SIZE'].sum(), thresholds = [1, 10, 15, 20, 30, 50, 100, 500])\n",
    "print(coverage_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach allows the same functions to be used directly on command line or implemented in an application, while maintaining clear traceability and reproducibility of the bioinformatics analyses.\n",
    "\n",
    "**Example of usage**:\n",
    "\n",
    "```bash\n",
    "python coverage_metrics.py <cram_path> <bed_path> <output_path> --gene_selection <GENE_NAME> --exon_selection <EXON_NUMBER> --method <method> --stats --output_plot <output_plot_path>\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
